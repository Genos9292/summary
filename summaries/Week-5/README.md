**Machine Translation**
-------------

[[nmt](https://github.com/eske/seq2seq/wiki/NMT---State-of-the-art)]

**[1]** Addressing the rare word problem in neural machine translation(2014). [[arxiv]](http://arxiv.org/pdf/1410.8206) [[PPT](http://slideplayer.com/slide/8898228/)] [[summary](https://gist.github.com/shagunsodhani/a18fe14b74c7292129c6c5ecb37f33b5)] [[code](https://github.com/sebastien-j/LV_groundhog/tree/master/experiments/nmt)] [[code](https://github.com/neubig/nmt-tips)] [[code](https://github.com/shawnxu1318/Google-Neural-Machine-Translation-GNMT)]

**[2]** Neural Machine Translation of Rare Words with Subword Units 2015. [[arxiv]](https://arxiv.org/pdf/1508.07909.pdf) [[PPT](https://www.slideshare.net/kanjitakahashi33/20161215neural-machine-translation-of-rare-words-with-subword-units)]  [[code](https://github.com/rsennrich/subword-nmt)] [[code](https://github.com/google/seq2seq/blob/master/docs/nmt.md)] [[code](https://github.com/claravania/subword-lstm-lm)] [[code](https://github.com/rsennrich/wmt16-scripts)] 

**[3]** Effective approaches to attention-based neural machine translation (2015). [[arxiv]](http://arxiv.org/pdf/1508.04025)  [[PPT](http://slideplayer.com/slide/7710523/)] [[PPT](https://sites.google.com/site/acl16nmt/)]  [[code](https://github.com/lmthang/nmt.matlab)] [[code](https://github.com/dillonalaird/Attention)] [[code](https://github.com/giancds/tsf_nmt)] [[code](https://github.com/tensorflow/nmt)] [[code](https://github.com/harvardnlp/seq2seq-attn)] [[code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py)] [[code](https://github.com/ZiyueHuang/MXSeq2Seq)] [[code](https://github.com/kacky24/articles/issues/4)]

**[4]** A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation 2016. [[arxiv]](https://arxiv.org/pdf/1603.06147.pdf) [[summary](https://github.com/0bserver07/Mah-Paper-Notes/blob/master/notes/Fully%20Character-Level%20Neural%20Machine%20Translation%20without%20Explicit%20Segmentation.md)] [[summary](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/char-level-decoder.md)] [[code](https://github.com/nyu-dl/dl4mt-cdec)] [[code](https://github.com/nyu-dl/dl4mt-c2c)] 

**[5]** Fully Character-Level Neural Machine Translation without Explicit Segmentation 2016. [[arxiv]](https://arxiv.org/pdf/1610.03017.pdf) [[summary](https://github.com/GokuMohandas/casual-digressions/blob/master/notes/fully_char.md)]  [[code](https://github.com/SwordYork/DCNMT)] 

**[6]** Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation 2016. [[arxiv]](https://arxiv.org/pdf/1609.08144v2.pdf) (Milestone) [[summary](http://wenchenli.github.io/2016/11/GNMT)] [[PPT](http://llcao.net/cu-deeplearning17/pp/class12_googletranslation.pdf)] 



**Robotics**
-----------------------
[[Sergey Levine from UC Berkeley](https://people.eecs.berkeley.edu/~svlevine/)]

**[1]** Evolving large-scale neural networks for vision-based reinforcement learning 2013. [[pdf]](http://repository.supsi.ch/4550/1/koutnik2013gecco.pdf) [[PPT](https://computing.ece.vt.edu/~f15ece6504/slides/L26_RL.pdf)] 

**[2]** End-to-end training of deep visuomotor policies (2016): 1-40. [[pdf]](http://www.jmlr.org/papers/volume17/15-522/15-522.pdf) 
[[PPT]()] [[summary](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/End-to-End_Training_of_Deep_Visuomotor_Policies.md)] [[PPT](https://pdfs.semanticscholar.org/15b9/12202d75ac67eb1dfbf39c00c74fea961e31.pdf)]  [[code](https://github.com/Kaixhin/end-to-end)] 

**[3]** Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours (2015). [[arxiv]](http://arxiv.org/pdf/1509.06825)  [[PPT](http://www.cs.columbia.edu/~allen/F17/NOTES/grasping_class.pdf)]     


**[4]** Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection (2016). [[arxiv]](http://arxiv.org/pdf/1603.02199)  [[PPT](http://robotics.itee.uq.edu.au/~PomdpInRobotics/slides/sergeyLevine-rss17PomdpWorkshop.pdf)] [[iee spectrum news](https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/google-large-scale-robotic-grasping-project)]

**[5]** Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning (2016). [[arxiv]](https://arxiv.org/pdf/1609.05143) [[PPT](http://slazebni.cs.illinois.edu/spring17/lec17_rl.pdf)] [[PPT](http://valser.org/2017/ppt/VOOC/valse_2017_lcw.pdf)] [[code](https://github.com/caomw/icra2017-visual-navigation)]

**[6]** Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search (2016). [[arxiv]](https://arxiv.org/pdf/1610.00673) 

**[7]** Deep Reinforcement Learning for Robotic Manipulation (2016). [[arxiv]](https://arxiv.org/pdf/1610.00633) 

**[8]** Sim-to-Real Robot Learning from Pixels with Progressive Nets (2016). [[arxiv]](https://arxiv.org/pdf/1610.04286.pdf) [[PPT](http://juxi.net/workshop/deep-learning-rss-2016/slides/Raia_Hadsell_RSS_DL_workshop.pdf)] [[PPT](https://rueckert.lima-city.de/NIPSWS2016/WebContent/slides/2016_12_09_NIPS-neurorobotics-workshop-Hadsell.pdf)] [[PPT](http://raiahadsell.com/uploads/3/6/4/2/36428762/erf2017_keynote_talk.pdf)] 


**[9]** Learning to navigate in complex environments (2016). [[arxiv]](https://arxiv.org/pdf/1611.03673) [[code](https://github.com/tgangwani/GA3C-DeepNavigation)]  

**Art**
--------------------------
[[neural style-code](https://github.com/topics/neural-style)]
**[1]** Inceptionism: Going Deeper into Neural Networks. [[html]](https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) (Deep Dream) [[PPT](http://6.869.csail.mit.edu/fa15/lecture/6.869-DeepLearningApplications3.pdf)] [[PPT](http://www3.cs.stonybrook.edu/~cse352/G15Dream.pdf)] [[PPT](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf)] 


**[2]** A neural algorithm of artistic style (2015). [[arxiv]](http://arxiv.org/pdf/1508.06576) (Outstanding Work, most successful method currently) [[PPT](http://web.cs.ucdavis.edu/~yjlee/teaching/ecs289g-fall2015/jchu2.pdf)] [[PPT](http://www.cs.ubc.ca/labs/lci/mlrg/slides/AST_slides.pdf)] [[PPT](https://www.slideshare.net/ckmarkohchang/a-neural-algorithm-of-artistic-style)] [[PPT](http://web.stanford.edu/class/cs20si/lectures/slides_06.pdf)]

**[3]** Generative Visual Manipulation on the Natural Image Manifold 2016. [[arxiv]](https://arxiv.org/pdf/1609.03552) (iGAN) [[PPT](http://people.eecs.berkeley.edu/~junyanz/projects/gvm/)] [[PPT](http://www.eccv2016.org/files/posters/P-4B-10.pdf)] [[PPT](https://www.reddit.com/r/MachineLearning/comments/52rqu2/generative_visual_manipulation_on_the_natural/)] [[PPT](http://aliensunmin.github.io/project/accv16tutorial/media/generative.pdf)] [[PPT](https://vision.cs.hacettepe.edu.tr/siu2017-tutorial/slides/tutorial_SIU2017_part3.pdf)] [[code](https://github.com/junyanz/iGAN)]

**[4]** Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks (2016). [[arxiv]](http://arxiv.org/pdf/1603.01768) (Neural Doodle) [[PPT](https://github.com/alexjc/neural-doodle)] [[PPT](http://www.cs.ubc.ca/labs/lci/mlrg/slides/AST_slides.pdf)] [[PPT](https://news.ycombinator.com/item?id=11257566)] [[[code](https://github.com/alexjc/neural-doodle)] [[code](https://github.com/DmitryUlyanov/fast-neural-doodle)] 

**[5]** Colorful Image Colorization (2016). [[arxiv]](http://arxiv.org/pdf/1603.08511) [[PPT](https://www.slideshare.net/harmonylab/colorful-image-colorization-76474734)] [[PPT](http://richzhang.github.io/colorization/)] [[PPT](https://www.cc.gatech.edu/~hays/compvision2016/lectures/38.pdf)] [[PPT](https://courses.cs.washington.edu/courses/cse590v/16au/slides/colorful_colorization.pdf)] [[PPT](http://www.eccv2016.org/files/posters/O-2B-03.pdf)] [[PPT](https://www.cs.unc.edu/~lazebnik/research/fall08/lec06_colorization.pdf)]

**[6]** Perceptual losses for real-time style transfer and super-resolution (2016). [[arxiv]](https://arxiv.org/pdf/1603.08155.pdf) [[PPT](https://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16.pdf)] [[PPT](https://cs.stanford.edu/people/jcjohns/papers/fast-style/fast-style-supp.pdf)] [[PPT](http://cs.stanford.edu/people/jcjohns/)] [[PPT](http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Real-Time_Neural_Style_CVPR_2017_paper.pdf)] [[PPT](https://dade-ai.github.io/paperclip/style/realtime.style/README.html)] [[code](https://github.com/jcjohnson/fast-neural-style)] [[PPT](https://www.slideshare.net/yusuketomoto/realtime-style-transfer-63669036)] 

**[7]** A learned representation for artistic style (2016). [[arxiv]](https://arxiv.org/pdf/1610.07629v1.pdf) [[PPT](http://web.stanford.edu/class/cs20si/lectures/slides_06.pdf)] [[PPT](https://github.com/handong1587/handong1587.github.io/blob/master/_posts/deep_learning/2015-10-09-fun-with-deep-learning.md)] [[PPT](https://openreview.net/forum?id=BJO-BuT1g)] [[PPT](http://web.cs.ucdavis.edu/~yjlee/teaching/ecs289g-fall2015/jchu2.pdf)] [[PPT](https://www.robots.ox.ac.uk/~vgg/rg/slides/weidi_rg.pdf)] [[code](https://github.com/joelmoniz/gogh-figure)] [[code](https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization)] [[code](https://github.com/anishathalye/neural-style)] [[code](https://github.com/robertomest/neural-style-keras)] [[code](https://github.com/andersbll/neural_artistic_style)] [[code](https://github.com/cysmith/neural-style-tf)] [[code](https://github.com/Heumi/Fast_Multi_Style_Transfer-tensorflow)] [[review](https://github.com/tensorflow/magenta/blob/master/magenta/reviews/styletransfer.md)] [[code](https://github.com/manumathewthomas/CS523Project1)] [[code](https://github.com/titu1994/Neural-Style-Transfer)]

**[8]** Controlling Perceptual Factors in Neural Style Transfer (2016). [[arxiv]](https://arxiv.org/pdf/1611.07865.pdf) (control style transfer over spatial location,colour information and across spatial scale)  [[code](https://github.com/leongatys/NeuralImageSynthesis)] [[code](https://github.com/jcjohnson/neural-style/issues/376)] [[code](https://github.com/leongatys/fast-neural-style)] [[code](https://github.com/leongatys)] [[code](https://github.com/xunhuang1995/AdaIN-style)] [[code](https://github.com/leongatys/PytorchNeuralStyleTransfer)]

**[9]** Texture Networks: Feed-forward Synthesis of Textures and Stylized Images(2016). [[arxiv]](http://arxiv.org/abs/1603.03417) (texture generation and style transfer) [[PPT](http://www.skoltech.ru/app/data/uploads/sites/2/2016/05/V.Lebedev-talk.pdf)]  [[code](https://github.com/DmitryUlyanov/texture_nets)] 

![gh](https://github.com/manumathewthomas/CS523Project1/blob/master/dataset.PNG)
![gh](https://raw.githubusercontent.com/titu1994/Neural-Style-Transfer/master/images/inputs/style/misty-mood-leonid-afremov.jpg)

<br>

**Object Segmentation**
-------------------------------

**[1]** Fully convolutional networks for semantic segmentation 2015. [[arxiv]](https://arxiv.org/pdf/1411.4038v2.pdf) [[PPT](http://slideplayer.com/slide/8902510/)] [[PPT](https://computing.ece.vt.edu/~f15ece6504/slides/L13_FCN.pdf)] [[PPT](http://techtalks.tv/talks/fully-convolutional-networks-for-semantic-segmentation/61606/)] [[PPT](https://moodle2.cs.huji.ac.il/nu15/pluginfile.php/435867/mod_resource/content/1/fcn_pres.pdf)] [[PPT](http://web.cs.ucdavis.edu/~yjlee/teaching/ecs289g-fall2015/philipp2.pdf)] [[code](https://github.com/shelhamer/fcn.berkeleyvision.org)]  [[PPT](http://cvlab.postech.ac.kr/~bhhan/class/cse703r_2016s/csed703r_lecture7.pdf)]  [[code](https://github.com/shekkizh/FCN.tensorflow)]  [[code](https://github.com/MarvinTeichmann/tensorflow-fcn)]  [[code](https://github.com/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation)]  [[code](https://github.com/aurora95/Keras-FCN)] [[code](https://github.com/Kaixhin/FCN-semantic-segmentation)]

**[2]** Semantic image segmentation with deep convolutional nets and fully connected crfs 2015. [[arxiv]](https://arxiv.org/pdf/1606.00915v1.pdf) [[PPT](http://liangchiehchen.com/projects/DeepLab.html)]  [[code](https://github.com/cdmh/deeplab-public)]  [[code](https://github.com/martinkersner/train-DeepLab)]  [[code](https://github.com/TheLegendAli/DeepLab-Context2)]  [[code](https://github.com/DrSleep/tensorflow-deeplab-resnet)]  [[code](https://github.com/xmyqsh/deeplab-v2)]  [[code](https://github.com/DrSleep/tensorflow-deeplab-lfov)] [[code](https://github.com/warmspringwinds/pytorch-segmentation-detection)] [[code](https://github.com/aharley/segaware/tree/master/caffe)] 

**[3]** Learning to segment object candidates. 2015. [[arxiv]](https://arxiv.org/pdf/1506.06204v2.pdf) [[PPT](http://www.cs.virginia.edu/~vicente/recognition/2016/presentations/deepmask.pdf)]   [[code](https://github.com/facebookresearch/deepmask)]  

**[4]** Instance-aware semantic segmentation via multi-task network cascades 2016 [[arxiv]](https://arxiv.org/pdf/1512.04412v1.pdf) [[PPT](http://web.eng.tau.ac.il/deep_learn/wp-content/uploads/2017/03/Multi-task-network-cascade.pdf)] [[PPT](http://imatge-upc.github.io/telecombcn-2016-dlcv/slides/D4L2-segmentation.pdf)]  [[code](https://github.com/daijifeng001/MNC)]  

**[5]** Instance-sensitive Fully Convolutional Networks (2016). [[arxiv]](https://arxiv.org/pdf/1603.08678v1.pdf) [[PPT](https://www.slideshare.net/mmisono/instancesensitive-fully-convolutional-networks)] [[PPT](http://image-net.org/challenges/talks/2016/ta-fcn_coco.pdf)] [[PPT](http://www.ics.uci.edu/~skong2/img/talk_compvis_2016Fall)] [[PPT]()] [[code](https://github.com/msracver/FCIS)]  [[code](https://github.com/ArcherFMY/Paper_Reading_List/tree/master/Instance-Aware-Paper-List)]  

