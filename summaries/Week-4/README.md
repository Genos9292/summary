**NLP(Natural Language Processing)**
----------------------------------

**[1]** Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing(2012) [[pdf]](https://www.hds.utc.fr/~bordesan/dokuwiki/lib/exe/fetch.php?id=en%3Apubli&cache=cache&media=en:bordes12aistats.pdf)
    [[PPT](https://www.slideshare.net/kushalarora11/nn-kb)] [[PPT](http://slideplayer.com/slide/5270778/)] [[PPT](https://cilvr.cs.nyu.edu/lib/exe/fetch.php?media=deeplearning:2015:dl-nyu-bordes.pdf)]
    
**[2]** Distributed representations of words and phrases and their compositionality(2013): 3111-3119 [[pdf]](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) (word2vec)
   [[PPT](http://people.ee.duke.edu/~lcarin/ChunyuanLi4.17.2015.pdf)] [[PPT](http://www.coli.uni-saarland.de/courses/comsem-15/material/Slides_Yauhen.pdf)] [[code](https://github.com/deborausujono/word2vecpy)]
   
**[3]** Sequence to sequence learning with neural networks(2014) [[pdf]](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)
   [[PPT](http://www.phontron.com/slides/neubig14taiwa11.pdf)] [[PPT](https://www.slideshare.net/indicods/general-sequence-learning-with-recurrent-neural-networks-for-next-ml)] [[PPT](https://www.slideshare.net/quangntta/sequence-to-sequence-learning-with-neural-networks)]
   
**[4]** Ask Me Anything: Dynamic Memory Networks for Natural Language Processing(2015) [[arxiv]](https://arxiv.org/abs/1506.07285)
   [[PPT](http://www.thespermwhale.com/jaseweston/icml2016/)] [[PPT](http://on-demand.gputechconf.com/gtc/2016/presentation/s6861-stephen-merity-dynamic-memory-networks.pdf)] [[PPT](https://www.slideshare.net/carpedm20/deep-reasoning)] [[PPT](http://www.icassp2016.org/SP16_PlenaryDeng_Slides.pdf)]
   
**[5]** Character-Aware Neural Language Models(2015) [[arxiv]](https://arxiv.org/abs/1508.06615)
   [[PPT](https://people.csail.mit.edu/dsontag/papers/kim_etal_AAAI16_slides.pdf)] [[PPT](https://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture13-highlight.pdf)] [[PPT](https://nlp.seas.harvard.edu/slides/aaai16.pdf)] [[code](https://github.com/carpedm20/lstm-char-cnn-tensorflow)] [[code](https://github.com/yoonkim/lstm-char-cnn)] [[code](https://github.com/jarfo/kchar)] [[code](https://github.com/jarfo/kchar)] [[code](https://github.com/dhyeon/character-aware-neural-language-models)]
   
**[6]** Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks(2015). [[pdf]](https://arxiv.org/abs/1502.05698) (bAbI tasks) 
  [[PPT](http://www.thespermwhale.com/jaseweston/icml2016/icml2016-memnn-tutorial.pdf)] [[code](https://github.com/facebook/bAbI-tasks)] [[code](https://github.com/vinhkhuc/MemN2N-babi-python)] [[code](https://github.com/Smerity/keras_qa)] [[code](https://github.com/siddk/relation-network)] [[code](https://github.com/ishalyminov/babi_tools)] [[code](https://github.com/raviraju/NLP_QA_Project)] [[code]()] 
  
**[7]** Teaching Machines to Read and Comprehend(2015) [[arxiv]](https://arxiv.org/abs/1506.03340) (CNN/DailyMail cloze style questions) 
   [[summary](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/teaching-machines-to-read-and-comprehend.md)] [[PPT](http://www.karlmoritz.com/publications)] [[PPT](http://lxmls.it.pt/2015/lxmls15.pdf)] [[PPT](http://egrefen.com/docs/HowMuchLinguistics2015.pdf)] [[code](https://github.com/thomasmesnard/DeepMind-Teaching-Machines-to-Read-and-Comprehend)] [[code](https://github.com/adbrebs/rnn_reader)] [[code](https://github.com/carpedm20/attentive-reader-tensorflow)] [[code](https://github.com/lhoang29/attentive-reader)] [[code](https://github.com/deepmind/rc-data)] [[code](https://github.com/soroushmehr/DeepMind-Teaching-Machines-to-Read-and-Comprehend?files=1)] [[code](https://github.com/KHN190/machine_compreh)]
   
**[8]** Very Deep Convolutional Networks for Natural Language Processing(2016) [[arxiv]](https://arxiv.org/abs/1606.01781) (state-of-the-art in text classification) [[code](https://github.com/lethienhoa/Very-Deep-Convolutional-Networks-for-Natural-Language-Processing)] [[code](https://github.com/geduo15/Very-Deep-Convolutional-Networks-for-Natural-Language-Processing-in-tensorflow)] [[code](https://github.com/geduo15/Very-Deep-Convolutional-Networks-for-Natural-Language-Processing-in-tensorflow/blob/master/Very-Deep-Convolutional-Networks-for-Text-Classification.ipynb)] [[code](https://github.com/hyperlex/vdcnn)] [[code](https://github.com/giacbrd/ShallowLearn)]
  
**[9]** Bag of Tricks for Efficient Text Classification(2016) [[arxiv]](https://arxiv.org/abs/1607.01759) (slightly worse than state-of-the-art, but a lot faster)
   [[summary](https://gist.github.com/shagunsodhani/432746f15889f7f4a798bf7f9ec4b7d8)] [[PPT](https://www.slideshare.net/lvcs_ucu/fasttext)] [[PPT](https://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture5-highlight.pdf)] [[code](https://github.com/facebookresearch/fastText)] [[code](https://github.com/poliglot/fasttext)] [[code](https://github.com/vrasneur/FastRText)] [[code](https://github.com/brightmart/text_classification)] [[code](https://github.com/salestock/fastText.py)] [[code](https://github.com/kemaswill/fasttext_torch)] [[code](https://github.com/vinhkhuc/JFastText)] [[code](https://github.com/sjhddh/fastText)] [[code](https://github.com/giacbrd/ShallowLearn)]
  
**Object Detection**
----------------------

**[1]** Deep neural networks for object detection 2013. [[pdf]](http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf) [[PPT](https://courses.cs.washington.edu/courses/cse590v/14au/cse590v_wk1_rcnn.pdf)] [[PPT](http://mmlab.ie.cuhk.edu.hk/resources/deep_learning/overview.pdf)] [[PPT](http://slazebni.cs.illinois.edu/spring17/lec07_detection.pdf)] [[PPT](http://www.isba2015.org/files/Deep_Learning_ISBA_2015.pdf)] [[PPT](https://cbmm.mit.edu/sites/default/files/documents/deep_neural_networks_tutorial.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-4/Object%20Detection/lec6a.ppt)] [[code](https://github.com/Sapphirine/Object_Detection_With_Deep_Neural_Networks)]

**[2]** Rich feature hierarchies for accurate object detection and semantic segmentation 2014. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf) (RCNN) [[PPT](http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf)] [[PPT](http://web.cs.ucdavis.edu/~yjlee/teaching/ecs289h-fall2014/CollinMcCarthy_RCNN.pdf)] [[PPT](http://slideplayer.com/slide/9209010/)] [[PPT](http://slideplayer.com/slide/1578290/)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-4/Object%20Detection/Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation.pptx)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-4/Object%20Detection/hossein_009_slides.pptx)] [[PPT](http://vision.cs.utexas.edu/381V-spring2016/slides/zheng-paper.pdf)] [[code](https://github.com/rbgirshick/rcnn)] 

**[3]** Spatial pyramid pooling in deep convolutional networks for visual recognition 2014. [[arxiv]](http://arxiv.org/pdf/1406.4729) (SPPNet) [[PPT](http://image-net.org/challenges/LSVRC/2014/slides/sppnet_ilsvrc2014.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-4/Object%20Detection/Spatial%20Pyramid%20Pooling%20in%20Deep%20Convolutional%20Networks%20for%20Visual%20Recognition.pptx)] [[PPT](http://slideplayer.com/slide/5277459/)] [[code](https://github.com/ShaoqingRen/SPP_net)] [[code](https://github.com/yhenon/keras-spp)] [[code](http://codegists.com/code/tensorflow-spatial-pyramid-pooling/)] 

**[4]**  Proceedings of the IEEE International Conference on Computer Vision. 2015. [[pdf]](https://pdfs.semanticscholar.org/8f67/64a59f0d17081f2a2a9d06f4ed1cdea1a0ad.pdf)  

**[5]** Faster R-CNN: Towards real-time object detection with region proposal networks**." Advances in neural information processing systems. 2015. [[pdf]](http://papers.nips.cc/paper/5638-analysis-of-variational-bayesian-latent-dirichlet-allocation-weaker-sparsity-than-map.pdf) [[PPT](https://www.slideshare.net/xavigiro/faster-rcnn-towards-realtime-object-detection-with-region-proposal-networks)] [[PPT](https://pdfs.semanticscholar.org/b24f/1f7e922ff9790091426d36622f4f03f04059.pdf)] [[PPT](http://imatge-upc.github.io/telecombcn-2016-dlcv/slides/D3L4-objects.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-4/Object%20Detection/rcnn_detection.pptx)] [[PPT](https://courses.engr.illinois.edu/ece420/sp2017/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf)] [[PPT](https://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf)] [[PPT](http://www.micc.unifi.it/bagdanov/pdfs/fast-rcnn-slides.pdf)] [[code](https://github.com/ShaoqingRen/faster_rcnn)] [[code](https://github.com/rbgirshick/py-faster-rcnn)] [[code](https://github.com/smallcorgi/Faster-RCNN_TF)] [[code](https://github.com/sridhar912/tsr-py-faster-rcnn)] [[code](https://github.com/yhenon/keras-frcnn)] [[code](https://github.com/longcw/faster_rcnn_pytorch)] [[code](https://github.com/endernewton/tf-faster-rcnn)] [[code](https://github.com/pengxj/action-faster-rcnn)]

**[6]** You only look once: Unified, real-time object detection (2015). [[pdf]](http://homes.cs.washington.edu/~ali/papers/YOLO.pdf) (YOLO,Oustanding Work, really practical) [[PPT](https://www.slideshare.net/xavigiro/you-only-look-once-unified-realtime-object-detection)] [[PPT](https://www.slideshare.net/TaegyunJeon1/pr12-you-only-look-once-yolo-unified-realtime-object-detection)] [[PPT](https://medium.com/towards-data-science/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006)] [[PPT](http://sglab.kaist.ac.kr/~sungeui/IR/Presentation/first_2016/%EA%B0%95%EB%AF%BC%EC%B2%A0.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-4/Object%20Detection/Presentation%20on%2009_16_2016%20by%20wenchi.pptx)] [[summary](https://github.com/abhshkdz/papers/blob/master/reviews/you-only-look-once-unified-real-time-object-detection.md)] [[summary](https://github.com/pjreddie/darknet/wiki/YOLO:-Real-Time-Object-Detection)] [[code](https://github.com/leggedrobotics/darknet_ros)] [[code](https://github.com/frischzenger/yolo-windows)] [[summary](https://github.com/aleju/papers/blob/master/neural-nets/YOLO.md)] [[code](https://pjreddie.com/darknet/yolo/)] [[code](https://pjreddie.com/darknet/yolo/)] [[code](https://github.com/unsky/yolo-for-windows-v2)] 

**[7]** SSD: Single Shot MultiBox Detector (2015). [[arxiv]](http://arxiv.org/pdf/1512.02325) [[PPT](https://www.slideshare.net/xavigiro/ssd-single-shot-multibox-detector)] [[PPT](https://www.slideshare.net/nmhkahn/single-shot-multibox-detector)] [[PPT](https://medium.com/@ManishChablani/ssd-single-shot-multibox-detector-explained-38533c27f75f)]  [[summary](https://github.com/Lab41/attalos/wiki/SSD)] [[summary](https://github.com/intel/caffe/wiki/SSD:-Single-Shot-MultiBox-Detector)] [[code](https://github.com/weiliu89/caffe/tree/ssd)] [[code](https://github.com/balancap/SSD-Tensorflow)] [[code](https://github.com/zhreshold/mxnet-ssd)] [[code](https://github.com/amdegroot/ssd.pytorch)] [[code](https://github.com/perrying/ssd-torch7)] [[code](https://github.com/rykov8/ssd_keras)] [[code](https://github.com/mks0601/SSD-Single-Shot-MultiBox-Detector)] 

**[8]** R-FCN: Object Detection via
Region-based Fully Convolutional Networks (2016). [[arxiv]](https://arxiv.org/abs/1605.06409) [[PPT](https://www.robots.ox.ac.uk/~vgg/rg/slides/vgg_rg_16_feb_2017_rfcn.pdf)] [[PPT](https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html)] [[PPT](http://people.ee.duke.edu/~lcarin/Kevin9.29.2017.pdf)]  [[code](https://github.com/daijifeng001/R-FCN)] [[code](https://github.com/YuwenXiong/py-R-FCN)] [[code](https://github.com/giorking/mx-rfcn)] [[code](https://github.com/PureDiors/pytorch_RFCN)]

**[9]** Mask R-CNN (2017). [[arxiv]](https://arxiv.org/abs/1703.06870) [[PPT]()] [[PPT]()] [[PPT]()] [[PPT]()] [[PPT]()] [[code](https://github.com/CharlesShang/FastMaskRCNN)] [[code](https://github.com/matterport/Mask_RCNN)] [[code](https://github.com/felixgwu/mask_rcnn_pytorch)] [[code](https://github.com/jasjeetIM/Mask-RCNN)]  [[code](https://github.com/TuSimple/mx-maskrcnn)]

**Visual Tracking**
----------------

**[1]** Learning a deep compact image representation for visual tracking 2013. [[pdf]](http://papers.nips.cc/paper/5192-learning-a-deep-compact-image-representation-for-visual-tracking.pdf) (First Paper to do visual tracking using Deep Learning,DLT Tracker)  [[PPT](http://mac.xmu.edu.cn/valse2017/ppt/APR/valse-2017-tracking_wy.pdf)] [[summay](https://github.com/handong1587/handong1587.github.io/blob/master/_posts/deep_learning/2015-10-09-tracking.md)] [[summary](https://github.com/foolwood/benchmark_results)]

**[2]** Transferring rich feature hierarchies for robust visual tracking (2015). [[arxiv]](http://arxiv.org/pdf/1501.04587) (SO-DLT) 

**[3]** Visual tracking with fully convolutional networks 2015. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf) (FCNT) [[PPT](http://cvlab.postech.ac.kr/~bhhan/class/cse703r_2016s/csed703r_lecture6.pdf)] [[PPT](https://www.camdemy.com/media/22088)]  [[code](https://github.com/torrvision/siamfc-tf)] [[code](https://github.com/scott89/FCNT)]

**[4]** Learning to Track at 100 FPS with Deep Regression Networks (2016). [[pdf]](http://arxiv.org/pdf/1604.01802) (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) [[PPT](http://16623.courses.cs.cmu.edu/slides/Lecture_17.pdf)]  [[code](https://github.com/autocyz/concise-GOTURN)] [[code](https://github.com/davheld/GOTURN)]

**[5]** Fully-Convolutional Siamese Networks for Object Tracking (2016). [[pdf]](https://arxiv.org/pdf/1606.09549) (SiameseFC,New state-of-the-art for real-time object tracking) [[PPT](http://16423.courses.cs.cmu.edu/slides/Spring_2017/Lecture_22.pdf)]  [[PPT](http://www.ittc.ku.edu/cviu/presentation/SiameseFC_10212016.pdf)][[code](https://github.com/bertinetto/siamese-fc)]

**[6]** Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking (2016) [[pdf]](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/C-COT_ECCV16.pdf) (C-COT)  [[PPT](https://pdfs.semanticscholar.org/c07a/8c62d4e9fd82f2e67a22374735b35893fbf9.pdf)] [[PPT](http://wasp-sweden.org/custom/uploads/2017/03/MartinDanelljan-poster.pdf)] [[code](https://github.com/martin-danelljan/ECO)] [[code]()] [[code](https://github.com/martin-danelljan/Continuous-ConvOp)]

**[7]** Modeling and Propagating CNNs in a Tree Structure for Visual Tracking (2016). [[arxiv]](https://arxiv.org/pdf/1608.07242) (VOT2016 Winner,TCNN)  

**Image Caption**
----------------
**[1]** Every picture tells a story: Generating sentences from images 2010. Springer Berlin Heidelberg:15-29, 2010. [[pdf]](https://www.cs.cmu.edu/~afarhadi/papers/sentence.pdf)

**[2]** Baby talk: Understanding and generating image descriptions 2011. [[pdf]](http://tamaraberg.com/papers/generation_cvpr11.pdf)

**[3]** Show and tell: A neural image caption generator 2014. [[arxiv]](https://arxiv.org/pdf/1411.4555.pdf)

**[4]** Long-term recurrent convolutional networks for visual recognition and description 2014. [[arxiv]](https://arxiv.org/pdf/1411.4389.pdf)

**[5]** Deep visual-semantic alignments for generating image descriptions 2014. [[pdf]](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)


**[6]** Deep fragment embeddings for bidirectional image sentence mapping 2014. [[arxiv]](https://arxiv.org/pdf/1406.5679v1.pdf)

**[7]** From captions to visual concepts and back 2014. [[arxiv]](https://arxiv.org/pdf/1411.4952v3.pdf)

**[8]** Learning a recurrent visual representation for image caption generation 2014. [[arxiv]](https://arxiv.org/pdf/1411.5654v1.pdf)

**[9]** Deep captioning with multimodal recurrent neural networks (m-rnn) 2014. [[arxiv]](https://arxiv.org/pdf/1412.6632v5.pdf)

**[10]** Show, attend and tell: Neural image caption generation with visual attention 2015. [[arxiv]](https://arxiv.org/pdf/1502.03044v3.pdf)
