**Neural Turing Machine**
----------------------------

**[39]** Neural turing machines(2014). [[arxiv]](http://arxiv.org/pdf/1410.5401.pdf) (Basic Prototype of Future Computer) [summary] [[code](https://github.com/carpedm20/NTM-tensorflow)] [[code](https://github.com/flomlo/ntm_keras)] [[code](https://github.com/snipsco/ntm-lasagne)] [[code](https://github.com/kaishengtai/torch-ntm)] [[code](https://github.com/jingweiz/pytorch-dnc)] [[code](https://github.com/shawntan/neural-turing-machines)] [[code](https://github.com/shawntan/neural-turing-machines)] [[PPT](http://klab.smpp.northwestern.edu/wiki/images/4/43/NTM2.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/Turing.ppt)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/lec27_memory.pptx)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/last_lecture.ppt)]

**[40]** Reinforcement learning neural Turing machines(2015). [[pdf]](https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf) [summary] 

**[41]** Memory networks(2014). [[arxiv]](http://arxiv.org/pdf/1410.3916) [summary] [[code](https://github.com/facebook/MemNN)] [[code](https://github.com/HendrikStrobelt/LSTMVis)]  [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/L19_MemNN.pptx)]  [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/abordes-lxmlss.pptx)]  [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/presentation_v07.pptx)]

**[42]** End-to-end memory networks(2015). [[pdf]](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf) [summary] [[code](https://github.com/carpedm20/MemN2N-tensorflow)]  [[code](https://github.com/vinhkhuc/MemN2N-babi-python)] [[code](https://github.com/domluna/memn2n)] [[code](https://github.com/npow/MemN2N)] [[code](https://github.com/ganeshjawahar/mem_absa)] [[PPT](http://www.cs.utoronto.ca/~fidler/teaching/2015/slides/CSC2523/marina_memnets.pdf)] [[PPT](https://pdfs.semanticscholar.org/10eb/d5c40277ecba4ed45d3dc12f9f1226720523.pdf)]

**[43]** Pointer networks(2015). [[pdf]](http://papers.nips.cc/paper/5866-pointer-networks.pdf) [summary] [[code](https://github.com/abisee/pointer-generator)] [[code](https://github.com/devsisters/pointer-network-tensorflow)] [[code](https://github.com/ikostrikov/TensorFlow-Pointer-Networks)] [[code](https://github.com/vshallc/PtrNets)] [[code](https://github.com/keon/pointer-networks)] [[PPT](http://download.mpi-inf.mpg.de/d2/mmalinow-slides/attention_networks.pdf)] 

**[44]** Hybrid computing using a neural network with dynamic external memory(2016). [[pdf]](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf) (Milestone,combine above papers' ideas) [summary] [[code](https://github.com/deepmind/dnc)] [[code](https://github.com/Mostafa-Samir/DNC-tensorflow)]  [[code](https://github.com/bgavran/DNC)]  [[code](https://github.com/claymcleod/tf-differentiable-neural-computer)]  [[code](https://github.com/greydanus/dnc)]  [[code](https://github.com/ypxie/pytorch-NeuCom)] [[PPT](https://courses.cs.ut.ee/MTAT.03.292/2016_fall/uploads/Main/externalmemory.pdf)] 

**Deep Reinforcement Learning**
------------------------

**[45]** Playing atari with deep reinforcement learning(2013). [[pdf]](http://arxiv.org/pdf/1312.5602.pdf)) (First Paper named deep reinforcement learning) [summary] [[code](https://github.com/kristjankorjus/Replicating-DeepMind)] [[code](https://github.com/gliese581gg/DQN_tensorflow)] [[code](https://github.com/daemonmaker/hedgehog)] [[code](https://github.com/Andy-P/DeepQLearning.jl)] [[PPT](http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf)] [[PPT](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Resources_files/deep_rl.pdf)] [[PPT](https://www.cl.cam.ac.uk/~pv273/slides/RL-PetarV-Presentation.pdf)] 

**[46]** Human-level control through deep reinforcement learning(2015). [[pdf]](https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf) (Milestone) [summary] [[code]()] [[code](https://github.com/devsisters/DQN-tensorflow)] [[code](https://github.com/whackashoe/Human_Level_Control_through_Deep_Reinforcement_Learning)] [[code](https://github.com/Kaixhin/human-level-control)] [[code](https://github.com/paengs/DQN)] [[code](https://github.com/meta-inf/dqn_caffe)] [[code](https://github.com/adepierre/Nature_Atari)]  [[PPT](https://www.slideshare.net/MuhammedKocaba/humanlevel-control-through-deep-reinforcement-learning-presentation)] [[PPT](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)] [[PPT](http://www.teach.cs.toronto.edu/~csc2542h/fall/material/csc2542f16_dqn.pdf)] [[PPT](http://llcao.net/cu-deeplearning15/presentation/DeepMindNature-preso-w-David-Silver-RL.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/ReinforcementLearning_part1.pptx)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/rl-function-approximation.pptx)]

**[47]** Dueling network architectures for deep reinforcement learning(2015). [[pdf]](http://arxiv.org/pdf/1511.06581) (ICLR best paper,great idea) [summary] [[code](https://github.com/carpedm20/deep-rl-tensorflow)] [[code](https://github.com/analog-rl/Duel_DDQN)] [[code](https://github.com/spiglerg/DQN_DDQN_Dueling_and_DDPG_Tensorflow)] [[code](https://github.com/musyoku/dueling-network)] [[code](https://github.com/ShangtongZhang/DeepRL)] [[code](https://github.com/matthiasplappert/keras-rl)] [[code](https://github.com/ZidanMusk/deep-RL-DQN-tensorflow)] [[code](https://github.com/yoosan/deeprl)] [[PPT](https://www.slideshare.net/carpedm20/dueling-network-architectures-for-deep-reinforcement-learning)] [[PPT](http://slazebni.cs.illinois.edu/spring17/lec17_rl.pdf)] [[PPT](http://icml.cc/2016/reviews/927.txt)] [[PPT](http://prediction-machines.com/wp-content/uploads/2017/07/Python-Meetup-Presentation.pdf)] [[PPT](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2017/Lecture/RL%20(v5).pdf)]

**[48]** Asynchronous methods for deep reinforcement learning(2016). [[pdf]](http://arxiv.org/pdf/1602.01783) (State-of-the-art method) [summary] [[code](https://github.com/coreylynch/async-rl)] [[code](https://github.com/miyosuda/async_deep_reinforce)] [[code](https://github.com/muupan/async-rl)] [[code](https://github.com/ikostrikov/pytorch-a3c)] [[code](https://github.com/Zeta36/Asynchronous-Methods-for-Deep-Reinforcement-Learning)] [[code](https://github.com/traai/async-deep-rl)] [[code](https://github.com/jaesik817/a3c-distributed_tensorflow)] [[code](https://github.com/Grzego/async-rl)] [[code](https://github.com/gliese581gg/batch-A3C_tensorflow)] [[PPT](https://lmb.informatik.uni-freiburg.de/lectures/seminar_brox/seminar_ss16/AsyncRL.pdf)] [[PPT](http://juxi.net/workshop/deep-learning-rss-2016/slides/Raia_Hadsell_RSS_DL_workshop.pdf)] [[PPT](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/RL%20(v6).pdf)] [[PPT](https://pdfs.semanticscholar.org/5e27/9a183435995cbafb09d87365c0e5c9103235.pdf)]

**[49]** Continuous control with deep reinforcement learning(2015). [[pdf]](http://arxiv.org/pdf/1509.02971) (DDPG) [summary] [[code](https://github.com/songrotek/DDPG)] [[code](https://github.com/stevenpjg/ddpg-aigym)] [[code](https://github.com/ahoereth/ddpg)] [[code](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow)] [[code](https://github.com/yanpanlau/DDPG-Keras-Torcs)] [[code](https://github.com/kengz/openai_lab)] [[code](https://github.com/rmst/ddpg)] [[code](https://github.com/songrotek/DDPG)]  [[code](https://github.com/ShangtongZhang/DeepRL)] [[code](https://github.com/vy007vikas/PyTorch-ActorCriticRL)] [[code](https://github.com/stormmax/reinforcement_learning)] [[PPT](https://www.slideshare.net/carpedm20/continuous-control-with-deep-reinforcement-learning-ddpg)] [[PPT](https://zhuanlan.zhihu.com/p/26754280)] [[PPT](http://web.stanford.edu/class/cs20si/lectures/slides_14.pdf)] [[PPT](https://learning.mpi-sws.org/mlss2016/slides/2016-MLSS-RL.pdf)] [[PPT](https://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf)] 

**[50]** Continuous Deep Q-Learning with Model-based Acceleration(2016). [[pdf]](http://arxiv.org/pdf/1603.00748) (NAF) [summary] [[code](https://github.com/carpedm20/NAF-tensorflow)] [[code](https://github.com/ikostrikov/pytorch-naf)] [[code](https://github.com/yenchenlin/DeepLearningFlappyBird)] [[code](https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner)] [[code](https://github.com/Conchylicultor/DeepQA)] [[code](https://github.com/spragunr/deep_q_rl)] [[PPT](https://www.slideshare.net/HyeminAhn/1118seminarcontinuousdeep-qlearning-with-model-based-acceleration)] [[PPT](https://www.slideshare.net/DeepLearningJP2016/dlcontinuous-deep-qlearning-with-modelbased-acceleration)] [[PPT](http://rll.berkeley.edu/deeprlcourse/f17docs/lecture_7_advanced_q_learning.pdf)] 

**[51]** Trust region policy optimization(2015). [[pdf]](http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf) (TRPO) [summary] [[code](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr)] [[code](https://github.com/openai/imitation)] [[code](https://github.com/pat-coady/trpo)] [[code](https://github.com/mjacar/pytorch-trpo)] [[code](https://github.com/ikostrikov/pytorch-trpo)] [[code](https://github.com/kvfrans/parallel-trpo)] [[code](https://github.com/jjkke88/trpo)] [[code](https://github.com/jjkke88/trpo)] [[PPT](http://www.cs.toronto.edu/~tingwuwang/trpo.pdf)] [[PPT](https://www.slideshare.net/mooopan/trust-region-policy-optimization)] [[PPT](https://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf)] [[PPT](http://yixinlin.net/trpo/presentation.pdf)] [[PPT](https://jmk.pe.kr/media/attachments/5bcf0aca45da310a434bbc093799c85e/trpo.pdf)] [[PPT](http://joschu.net/docs/thesis.pdf)]

**[52]** Mastering the game of Go with deep neural networks and tree search(2016). [[pdf]](http://willamette.edu/~levenick/cs448/goNature.pdf) (AlphaGo) [summary] [[code](https://github.com/brilee/MuGo)] [[code](https://github.com/maxpumperla/betago)] [[code](https://github.com/chncwang/FoolGo)] [[code](https://github.com/gcp/leela-zero)] [[code](https://github.com/Rochester-NRT/RocAlphaGo.data)] [[code](https://github.com/pycharming/AlphaGo)] [[code](https://github.com/yenw/computer-go-dataset)] [[code](https://github.com/alphagov/alphagov.github.io)] [[PPT](https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf)] [[PPT](https://www.slideshare.net/KarelHa1/mastering-the-game-of-go-with-deep-neural-networks-and-tree-search-presentation)] [[PPT](https://www.slideshare.net/SanFengChang/mastering-the-game-of-go-with-deep-neural-networks-and-tree-search)] [[PPT](http://www3.cs.stonybrook.edu/~cse634/G6present.pdf)] [[PPT](https://cs.uwaterloo.ca/~nasghar/alphagoslides.pdf)] [[PPT](http://classes.engr.oregonstate.edu/eecs/spring2017/cs331/slides/alpha-go.2pp.pdf)] [[PPT](https://www.reddit.com/r/MachineLearning/comments/42ytdx/pdf_mastering_the_game_of_go_with_deep_neural/?st=j975g88c&sh=bbbc611b)] [[PPT](https://deepmind.com/research/alphago/)]



**Deep Transfer Learning / Lifelong Learning / especially for RL**
---------------------
**[53]** Deep Learning of Representations for Unsupervised and Transfer Learning(2012). [[pdf]](http://www.jmlr.org/proceedings/papers/v27/bengio12a/bengio12a.pdf) (A Tutorial) [summary] [code] [PPT]
**[54]** Lifelong Machine Learning Systems: Beyond Learning Algorithms(2013). [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.696.7800&rep=rep1&type=pdf) (A brief discussion about lifelong learning) [summary] [[PPT](http://slideplayer.com/slide/6220039/)] [[PPT](https://www.slideshare.net/xavigiro/lifelong-incremental-learning-d3l2-2017-upc-deep-learning-for-computer-vision)] [[PPT](https://www.cs.uic.edu/~liub/Lifelong-Learning-tutorial-slides.pdf)] [[PPT](https://www.slideshare.net/guard0g/beyond-machine-learning-the-new-generation-of-learning-algorithms-coming-to-market)]

**[55]** Distilling the knowledge in a neural network(2015). [[arxiv]](http://arxiv.org/pdf/1503.02531) (Godfather's Work) [summary]  [[PPT](http://www.ttic.edu/dl/dark14.pdf)] [[PPT](https://www.slideshare.net/AlexanderKorbonits/distilling-dark-knowledge-from-neural-networks)] [[PPT](http://homepages.inf.ed.ac.uk/s1459647/posters/distilling_model_knowledge.pdf)] [[PPT](https://stanford.edu/~rezab/nips2014workshop/slides/jeff.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/20160616_yang_v2_Distilling%20the%20Knowledge%20in%20a%20Neural%20Network.pptx)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/Distilling_Knowledge_in_a_Neural_Network.pptx)]

**[56]** Policy distillation(2015). [[arxiv]](http://arxiv.org/pdf/1511.06295) (RL domain) [summary]  [[PPT](http://www.ntu.edu.sg/home/sinnopan/publications/[AAAI17]Knowledge%20Transfer%20for%20Deep%20Reinforcement%20Learning%20with%20Hierarchical%20Experience%20Replay.pdf)]

**[57]** Actor-mimic: Deep multitask and transfer reinforcement learning(2015). [[arxiv]](http://arxiv.org/pdf/1511.06342) (RL domain) [summary]

**[58]** Progressive neural networks(2016). [[arxiv]](https://arxiv.org/pdf/1606.04671) (Outstanding Work, A novel idea)  [summary]


**One Shot Deep Learning**
---------------
**[59]** Human-level concept learning through probabilistic program induction. [[pdf]](http://clm.utexas.edu/compjclub/wp-content/uploads/2016/02/lake2015.pdf) (No Deep Learning,but worth reading)

**[60]** Siamese Neural Networks for One-shot Image Recognition(2015) [[pdf]](http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf) 

**[61]** One-shot Learning with Memory-Augmented Neural Networks(2016). [[arxiv]](http://arxiv.org/pdf/1605.06065) **(A basic step to one shot learning)

**[62]** Matching Networks for One Shot Learning(2016). [[arxiv]](https://arxiv.org/pdf/1606.04080)

**[63]** Low-shot visual object recognition**." arXiv preprint arXiv:1606.02819 (2016). [[arxiv]](http://arxiv.org/pdf/1606.02819) (A step to large data)
