**Neural Turing Machine**
----------------------------

**[39]** Neural turing machines(2014). [[arxiv]](http://arxiv.org/pdf/1410.5401.pdf) (Basic Prototype of Future Computer) [summary] [[code](https://github.com/carpedm20/NTM-tensorflow)] [[code](https://github.com/flomlo/ntm_keras)] [[code](https://github.com/snipsco/ntm-lasagne)] [[code](https://github.com/kaishengtai/torch-ntm)] [[code](https://github.com/jingweiz/pytorch-dnc)] [[code](https://github.com/shawntan/neural-turing-machines)] [[code](https://github.com/shawntan/neural-turing-machines)] [[PPT](http://klab.smpp.northwestern.edu/wiki/images/4/43/NTM2.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/Turing.ppt)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/lec27_memory.pptx)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/last_lecture.ppt)]

**[40]** Reinforcement learning neural Turing machines(2015). [[pdf]](https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf) [summary] 

**[41]** Memory networks(2014). [[arxiv]](http://arxiv.org/pdf/1410.3916) [summary] [[code](https://github.com/facebook/MemNN)] [[code](https://github.com/HendrikStrobelt/LSTMVis)]  [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/L19_MemNN.pptx)]  [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/abordes-lxmlss.pptx)]  [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/presentation_v07.pptx)]

**[42]** End-to-end memory networks(2015). [[pdf]](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf) [summary] [[code](https://github.com/carpedm20/MemN2N-tensorflow)]  [[code](https://github.com/vinhkhuc/MemN2N-babi-python)] [[code](https://github.com/domluna/memn2n)] [[code](https://github.com/npow/MemN2N)] [[code](https://github.com/ganeshjawahar/mem_absa)] [[PPT](http://www.cs.utoronto.ca/~fidler/teaching/2015/slides/CSC2523/marina_memnets.pdf)] [[PPT](https://pdfs.semanticscholar.org/10eb/d5c40277ecba4ed45d3dc12f9f1226720523.pdf)]

**[43]** Pointer networks(2015). [[pdf]](http://papers.nips.cc/paper/5866-pointer-networks.pdf) [summary] [[code](https://github.com/abisee/pointer-generator)] [[code](https://github.com/devsisters/pointer-network-tensorflow)] [[code](https://github.com/ikostrikov/TensorFlow-Pointer-Networks)] [[code](https://github.com/vshallc/PtrNets)] [[code](https://github.com/keon/pointer-networks)] [[PPT](http://download.mpi-inf.mpg.de/d2/mmalinow-slides/attention_networks.pdf)] 

**[44]** Hybrid computing using a neural network with dynamic external memory(2016). [[pdf]](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf) (Milestone,combine above papers' ideas) [summary] [[code](https://github.com/deepmind/dnc)] [[code](https://github.com/Mostafa-Samir/DNC-tensorflow)]  [[code](https://github.com/bgavran/DNC)]  [[code](https://github.com/claymcleod/tf-differentiable-neural-computer)]  [[code](https://github.com/greydanus/dnc)]  [[code](https://github.com/ypxie/pytorch-NeuCom)] [[PPT](https://courses.cs.ut.ee/MTAT.03.292/2016_fall/uploads/Main/externalmemory.pdf)] 

**Deep Reinforcement Learning**
------------------------

**[45]** Playing atari with deep reinforcement learning(2013). [[pdf]](http://arxiv.org/pdf/1312.5602.pdf)) (First Paper named deep reinforcement learning) [summary] [[code](https://github.com/kristjankorjus/Replicating-DeepMind)] [[code](https://github.com/gliese581gg/DQN_tensorflow)] [[code](https://github.com/daemonmaker/hedgehog)] [[code](https://github.com/Andy-P/DeepQLearning.jl)] [[PPT](http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf)] [[PPT](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Resources_files/deep_rl.pdf)] [[PPT](https://www.cl.cam.ac.uk/~pv273/slides/RL-PetarV-Presentation.pdf)] 

**[46]** Human-level control through deep reinforcement learning(2015). [[pdf]](https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf) (Milestone) [summary] [[code]()] [[code](https://github.com/devsisters/DQN-tensorflow)] [[code](https://github.com/whackashoe/Human_Level_Control_through_Deep_Reinforcement_Learning)] [[code](https://github.com/Kaixhin/human-level-control)] [[code](https://github.com/paengs/DQN)] [[code](https://github.com/meta-inf/dqn_caffe)] [[code](https://github.com/adepierre/Nature_Atari)]  [[PPT](https://www.slideshare.net/MuhammedKocaba/humanlevel-control-through-deep-reinforcement-learning-presentation)] [[PPT](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)] [[PPT](http://www.teach.cs.toronto.edu/~csc2542h/fall/material/csc2542f16_dqn.pdf)] [[PPT](http://llcao.net/cu-deeplearning15/presentation/DeepMindNature-preso-w-David-Silver-RL.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/ReinforcementLearning_part1.pptx)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-3/ppt/rl-function-approximation.pptx)]

**[47]** Dueling network architectures for deep reinforcement learning(2015). [[pdf]](http://arxiv.org/pdf/1511.06581) (ICLR best paper,great idea) [summary] [[code](https://github.com/carpedm20/deep-rl-tensorflow)] [[code](https://github.com/analog-rl/Duel_DDQN)] [[code](https://github.com/spiglerg/DQN_DDQN_Dueling_and_DDPG_Tensorflow)] [[code](https://github.com/musyoku/dueling-network)] [[code](https://github.com/ShangtongZhang/DeepRL)] [[code](https://github.com/matthiasplappert/keras-rl)] [[code](https://github.com/ZidanMusk/deep-RL-DQN-tensorflow)] [[code](https://github.com/yoosan/deeprl)] [[PPT](https://www.slideshare.net/carpedm20/dueling-network-architectures-for-deep-reinforcement-learning)] [[PPT](http://slazebni.cs.illinois.edu/spring17/lec17_rl.pdf)] [[PPT](http://icml.cc/2016/reviews/927.txt)] [[PPT](http://prediction-machines.com/wp-content/uploads/2017/07/Python-Meetup-Presentation.pdf)] [[PPT](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2017/Lecture/RL%20(v5).pdf)]

**[48]** Asynchronous methods for deep reinforcement learning(2016). [[pdf]](http://arxiv.org/pdf/1602.01783) (State-of-the-art method) [summary] [[code](https://github.com/coreylynch/async-rl)] [[code](https://github.com/miyosuda/async_deep_reinforce)] [[code](https://github.com/muupan/async-rl)] [[code](https://github.com/ikostrikov/pytorch-a3c)] [[code](https://github.com/Zeta36/Asynchronous-Methods-for-Deep-Reinforcement-Learning)] [[code](https://github.com/traai/async-deep-rl)] [[code](https://github.com/jaesik817/a3c-distributed_tensorflow)] [[code](https://github.com/Grzego/async-rl)] [[code](https://github.com/gliese581gg/batch-A3C_tensorflow)] [[PPT](https://lmb.informatik.uni-freiburg.de/lectures/seminar_brox/seminar_ss16/AsyncRL.pdf)] [[PPT](http://juxi.net/workshop/deep-learning-rss-2016/slides/Raia_Hadsell_RSS_DL_workshop.pdf)] [[PPT](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/RL%20(v6).pdf)] [[PPT](https://pdfs.semanticscholar.org/5e27/9a183435995cbafb09d87365c0e5c9103235.pdf)]

**[49]** Continuous control with deep reinforcement learning(2015). [[pdf]](http://arxiv.org/pdf/1509.02971) (DDPG) [summary] [code] [PPT] 

**[50]** Continuous Deep Q-Learning with Model-based Acceleration(2016). [[pdf]](http://arxiv.org/pdf/1603.00748) (NAF) [summary] [code] [PPT] 

**[51]** Trust region policy optimization(2015). [[pdf]](http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf) (TRPO) [summary] [code] [PPT] 

**[52]** Mastering the game of Go with deep neural networks and tree search(2016). [[pdf]](http://willamette.edu/~levenick/cs448/goNature.pdf) (AlphaGo) [summary] [code] [PPT] 
