
**Model**
------------------------------
**[14]** Improving neural networks by preventing co-adaptation of feature detectors. [[pdf]](https://arxiv.org/pdf/1207.0580.pdf) (Dropout)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/mdenil/dropout)] [[code](https://github.com/dnouri/cuda-convnet)] [[PPT](http://www.ke.tu-darmstadt.de/lehre/archiv/ws-13-14/seminarML/slides/folien13_Laux.pdf)]

**[15]** Dropout: a simple way to prevent neural networks from overfitting [[pdf]](http://www.jmlr.org/papers/volume15/srivastava14a.old/source/srivastava14a.pdf)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/yaringal/ConcreteDropout)] [[code](https://github.com/Philip-Bachman/NN-Dropout)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-2/Lecture_04_Supervised_Pretraining.pptx)]

**[16]** Batch normalization: Accelerating deep network training by reducing internal covariate shift(2015). [[pdf]](http://arxiv.org/pdf/1502.03167) (An outstanding Work in 2015)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/ChenglongChen/batch_normalization)] [[code](https://github.com/shuuki4/Batch-Normalization)] [[code](https://github.com/hwalsuklee/tensorflow-mnist-MLP-batch_normalization-weight_initializers)] [[code](https://github.com/ChenglongChen/batch_normalization)] [[PPT](http://people.ee.duke.edu/~lcarin/Zhao12.17.2015.pdf)]

**[17]** Layer normalization (2016). [[pdf]](https://arxiv.org/pdf/1607.06450.pdf?utm_source=sciontist.com&utm_medium=refer&utm_campaign=promote) (Update of Batch Normalization)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/ryankiros/layer-norm)] [[code](https://github.com/carlthome/tensorflow-convlstm-cell)]  [[code](https://github.com/pbhatia243/tf-layer-norm)] [[code](https://github.com/MycChiu/fast-LayerNorm-TF)] [PPT]

**[18]** Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or−1." [[pdf]](https://pdfs.semanticscholar.org/f832/b16cb367802609d91d400085eb87d630212a.pdf) (New Model,Fast)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/codekansas/tinier-nn)] [[code](https://github.com/MatthieuCourbariaux/BinaryNet)] [[code](https://github.com/TianweiXing/BNN)] [[code](https://github.com/cornell-zhang/bnn-fpga)] [[PPT](http://web.eng.tau.ac.il/deep_learn/wp-content/uploads/2017/03/Binary-Deep-Learning.pdf)]

**[19]** Decoupled neural interfaces using synthetic gradients. [[pdf]](https://arxiv.org/pdf/1608.05343) (Innovation of Training Method,Amazing Work)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/andrewliao11/dni.pytorch)] [[code](https://github.com/vyraun/DNI-tensorflow)] [[PPT](https://www.slideshare.net/Eniod/019-20160907-decoupled-neural-interfaces-using-synthetic-gradients)]

**[20]** Net2net: Accelerating learning via knowledge transfer.(2015). [[pdf]](https://arxiv.org/abs/1511.05641) (Modify previously trained network to reduce training epochs)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/soumith/net2net.torch)] [[code](https://github.com/DanielSlater/Net2Net)] [[code](https://github.com/paengs/Net2Net)] [[code](https://github.com/erogol/Net2Net)] [PPT]

**[21]** Network Morphism. [[pdf]](https://arxiv.org/abs/1603.01670) (Modify previously trained network to reduce training epochs)

✔ [[summary]]  [revisit-notes] [code] [PPT]


**Optimization**
---------------------------------------
**[22]** On the importance of initialization and momentum in deep learning. [[pdf]](http://www.jmlr.org/proceedings/papers/v28/sutskever13.pdf) (Momentum optimizer)

✔ [[summary]]  [revisit-notes] [code] [PPT] 

**[23]** Adam: A method for stochastic optimization. [[pdf]](http://arxiv.org/pdf/1412.6980) (Maybe used most often currently)

✔ [[summary]]  [revisit-notes] [code] [[PPT](https://moodle2.cs.huji.ac.il/nu15/pluginfile.php/316969/mod_resource/content/1/adam_pres.pdf)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-2/Adam_slides.pdf)]

**[24]** Learning to learn by gradient descent by gradient descent(2016). [[pdf]](https://arxiv.org/pdf/1606.04474) (Neural Optimizer,Amazing Work)

✔ [[summary]]  [revisit-notes] [code] [PPT]

**[25]** Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding. [[pdf]](https://pdfs.semanticscholar.org/5b6c/9dda1d88095fa4aac1507348e498a1f2e863.pdf) (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup)

✔ [[summary]]  [revisit-notes] [code] [[PPT](http://on-demand.gputechconf.com/gtc/2016/presentation/s6561-song-han-deep-compression.pdf)] [[PPT](https://web.stanford.edu/class/ee380/Abstracts/160106-slides.pdf)]

**[26]** SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size(2016). [[pdf]](http://arxiv.org/pdf/1602.07360) (Also a new direction to optimize NN,DeePhi Tech Startup)

✔ [[summary]]  [revisit-notes] [code] [[PPT](http://statsmaths.github.io/stat665/lectures/lec19/lecture19.pdf)]


**Unsupervised Learning / Deep Generative Model**
------------------------------
**[27]** Building high-level features using large scale unsupervised learning. [[arXiv](https://arxiv.org/abs/1112.6209)] (Milestone, Andrew Ng, Google Brain Project, Cat) 

✔ [[summary]]  [revisit-notes] [code] [[PPT]]

**[28]** Auto-encoding variational bayes.(2013). [[arXiv](https://arxiv.org/abs/1312.6114)] (VAE)

✔ [[summary]]  [revisit-notes] [code] [[PPT](http://dpkingma.com/wordpress/wp-content/uploads/2014/05/2014-03_talk_iclr.pdf)] [[PPT](http://www.mlsalt.eng.cam.ac.uk/foswiki/pub/Main/ClassOf2017/D423C_poster.pdf)] [[PPT](http://people.ee.duke.edu/~lcarin/DEC9.26.2014.pdf)]

**[29]** Generative adversarial nets.2014. [[arXiv](https://arxiv.org/abs/1406.2661)] (GAN,super cool idea)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/junyanz/CycleGAN)] [[code](https://github.com/ckmarkoh/GAN-tensorflow)] [[PPT](https://www.slideshare.net/ssuser77ee21/generative-adversarial-networks-70896091)] [[PPT](https://www.slideshare.net/ckmarkohchang/generative-adversarial-networks)] [[PPT](http://dl.ee.cuhk.edu.hk/slides/gan.pdf)] [[PPT](http://www.cs.toronto.edu/~dtarlow/pos14/talks/goodfellow.pdf)] [[PPT](http://pages.cs.wisc.edu/~dpage/cs760/GANs.pdf)] [[PPT](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf)] [[PPT](http://slazebni.cs.illinois.edu/spring17/lec11_gan.pdf)]

**[30]** Unsupervised representation learning with deep convolutional generative adversarial networks.(2015). [[arXiv](https://arxiv.org/abs/1511.06434)] (DCGAN)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/Newmu/dcgan_code)] [[code](https://github.com/soumith/dcgan.torch)] [[code](https://github.com/mattya/chainer-DCGAN)] [[code](https://github.com/jacobgil/keras-dcgan)] [[code](https://github.com/YadiraF/GAN)] [[code](https://github.com/carpedm20/DCGAN-tensorflow)] [[PPT](http://aliensunmin.github.io/project/accv16tutorial/media/generative.pdf)]

**[31]** DRAW: A recurrent neural network for image generation.(2015). [[arXiv](https://arxiv.org/abs/1502.04623)] (VAE with attention, outstanding work)

✔ [[summary]]  [revisit-notes] [[code](https://github.com/ikostrikov/TensorFlow-VAE-GAN-DRAW)] [[code](https://github.com/ericjang/draw)] [[code](https://github.com/jbornschein/draw)] [[code](https://github.com/vivanov879/draw)] [[code]()] [[PPT](http://people.ee.duke.edu/~lcarin/Zhe10.2.2015.pdf)] [[PPT](http://cs231n.stanford.edu/slides/2016/winter1516_lecture10.pdf)]

**[32]** Pixel recurrent neural networks.(2016). [[arXiv](https://arxiv.org/abs/1601.06759)] (PixelRNN)

✔ [[summary](https://gist.github.com/shagunsodhani/e741ebd5ba0e0fc0f49d7836e30891a7)] [[summay](https://github.com/sunshineatnoon/Paper-Collection/blob/master/pixel-rnn.md)] [revisit-notes] [[code](https://github.com/tensorflow/magenta/blob/master/magenta/reviews/pixelrnn.md)] [[code](https://github.com/carpedm20/pixel-rnn-tensorflow)] [[code](https://github.com/igul222/pixel_rnn)]  [[code]()] [[PPT](https://www.slideshare.net/neouyghur/pixel-recurrent-neural-networks-73970786)] [[PPT](https://github.com/gopala-kr/summary/blob/master/summaries/Week-2/lec10new.ppt)] [[PPT](http://imatge-upc.github.io/telecombcn-2016-dlcv/slides/D2L6-recurrent.pdf)] [[PPT](https://github.com/sunshineatnoon/Paper-Collection/blob/master/pixel-rnn.md)]

**[33]** Conditional image generation with PixelCNN decoders.(2016). [[arXiv](https://arxiv.org/abs/1606.05328)] (PixelCNN)

✔ [[summary](https://github.com/aleju/papers/blob/master/neural-nets/Conditional_Image_Generation_with_PixelCNN_Decoders.md)] [[summary](https://gist.github.com/shagunsodhani/3cc7066ce7de051d769908b8fab11990)]  [revisit-notes] [[code](https://github.com/anantzoid/Conditional-PixelCNN-decoder)] [[code](https://github.com/openai/pixel-cnn)] [[code](https://github.com/carpedm20/pixel-rnn-tensorflow)] [[code](https://github.com/kundan2510/pixelCNN)] [[code](https://github.com/dritchie/pixelCNN)] [[PPT](https://www.slideshare.net/suga93/conditional-image-generation-with-pixelcnn-decoders)] [[PPT](http://slazebni.cs.illinois.edu/spring17/lec13_advanced.pdf)]

